{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 22\n",
      "Compression ratio: 1.00\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and normalize the text.\"\"\"\n",
    "    # Removing punctuation and unnecessary characters\n",
    "    text = re.sub(r\"[^\\u0900-\\u097F\\s]\", \"\", text)  # Keep Hindi characters and spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def calculate_compression_ratio(corpus, tokenized_corpus):\n",
    "    \"\"\"Calculate the compression ratio.\"\"\"\n",
    "    original_length = len(\"\".join(corpus))\n",
    "    tokenized_length = sum(len(token) for token in tokenized_corpus)\n",
    "    return original_length / tokenized_length\n",
    "\n",
    "def build_bpe(corpus, vocab_size):\n",
    "    \"\"\"Build a BPE vocabulary.\"\"\"\n",
    "    # Tokenize corpus into characters\n",
    "    corpus = [\" \".join(word) + \" </w>\" for word in corpus]\n",
    "    corpus = \" \".join(corpus).split()\n",
    "    \n",
    "    # Count initial token frequencies\n",
    "    token_freqs = Counter(corpus)\n",
    "    bpe_vocab = set(token_freqs.keys())\n",
    "    \n",
    "    while len(bpe_vocab) < vocab_size:\n",
    "        # Count all pairs of symbols\n",
    "        pairs = defaultdict(int)\n",
    "        for word in token_freqs.keys():\n",
    "            symbols = word.split()\n",
    "            for i in range(len(symbols) - 1):\n",
    "                pairs[symbols[i], symbols[i + 1]] += token_freqs[word]\n",
    "        \n",
    "        if not pairs:\n",
    "            break\n",
    "        \n",
    "        # Get the most frequent pair\n",
    "        best_pair = max(pairs, key=pairs.get)\n",
    "        new_symbol = \"\".join(best_pair)\n",
    "        \n",
    "        # Replace the best pair in the vocabulary\n",
    "        new_vocab = {}\n",
    "        for word, freq in token_freqs.items():\n",
    "            new_word = re.sub(r\"\\b\" + re.escape(\" \".join(best_pair)) + r\"\\b\", new_symbol, word)\n",
    "            new_vocab[new_word] = freq\n",
    "        \n",
    "        token_freqs = new_vocab\n",
    "        bpe_vocab.add(new_symbol)\n",
    "    \n",
    "    return bpe_vocab\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example Hindi text corpus\n",
    "    hindi_corpus = [\n",
    "        \"नमस्ते दुनिया\", \n",
    "        \"भारत एक सुंदर देश है\", \n",
    "        \"हिंदी एक सुंदर भाषा है\"\n",
    "    ]\n",
    "    hindi_corpus = [preprocess_text(sentence) for sentence in hindi_corpus]\n",
    "    \n",
    "    # Building BPE vocabulary\n",
    "    vocab_size = 5000\n",
    "    bpe_vocab = build_bpe(hindi_corpus, vocab_size)\n",
    "    \n",
    "    # Calculate compression ratio\n",
    "    tokenized_corpus = [\" \".join(word.split()) for word in hindi_corpus]\n",
    "    compression_ratio = calculate_compression_ratio(hindi_corpus, tokenized_corpus)\n",
    "    \n",
    "    print(f\"Vocabulary size: {len(bpe_vocab)}\")\n",
    "    print(f\"Compression ratio: {compression_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
